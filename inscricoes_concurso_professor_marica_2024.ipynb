{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de dados das inscrições para o concurso público da SEMED da Prefeitura de Maricá (2024)\n",
    "\n",
    "### Este projeto visa coletar, tratar e analisar os dados da Lista Geral Preliminar das inscrições confirmadas para o concurso público da SEMED da Prefeitura de Maricá\n",
    "### Url do arquivo: https://portal.coseac.uff.br/wp-content/uploads/sites/596/2024/04/Concurso-PMM-SEMED20241-ListaGeralPreliminardasinscricoesconfirmadas.pdf\n",
    "### Data de acesso: 02 de maio de 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise inicial do arquivo pdf\n",
    "### Número de páginas: 1994\n",
    "### Característiras: Todas as páginas apresentam-se padronizadas com a seguite estrutura:\n",
    "### - Cabeçalho;\n",
    "### - Conteúdo: \n",
    "Tabela com dados:\n",
    "    Colunas: Inscrição, Requerimento, Nome do Candidato, Data de Nascimento, Cargo, Tipo de Vaga.\n",
    "    Linhas: cada linha contém as informações sobre uma inscrição;\n",
    "### - Rodapé com legendas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Python utilizadas:\n",
    "### - pdfplumber: para a leitura do arquivo\n",
    "### - pandas: para a limpeza e tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código para auxílio na análise exploratória.\n",
    "### Verificando se os cabeçalhos de todas as páginas são iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"Concurso-PMM-SEMED20241-ListaGeralPreliminardasinscricoesconfirmadas.pdf\"\n",
    "\n",
    "with pdfplumber.open(path_to_file) as pdf:\n",
    "    page_0_header = [pdf.pages[0].extract_text().split(\"\\n\")[i] for i in range(8) if i != 2]\n",
    "    \n",
    "    for i in range(0, 1994):\n",
    "        page = pdf.pages[i]\n",
    "        text = page.extract_text()\n",
    "        page_x_header = [text.split(\"\\n\")[i] for i in range(8) if i != 2]\n",
    "        \n",
    "        if page_0_header != page_x_header:\n",
    "            page_number = text.split(\"\\n\")[2]\n",
    "            advise = f'There is diferent header on the page {page_number}'\n",
    "            print(advise)\n",
    "            break\n",
    "    \n",
    "    print(\"All headers are the same!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando e preenchendo uma lista que será usada na geração do dataframe inicial.\n",
    "### Colunas selecionadas: Cargo pretendido e Tipo de vaga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"Concurso-PMM-SEMED20241-ListaGeralPreliminardasinscricoesconfirmadas.pdf\"\n",
    "all_lines_to_dataframe = [[\"Cargo\", \"TipoVaga\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cargo_column(unformated_line):\n",
    "    docente_position = 0\n",
    "    for j in range(len(unformated_line)):\n",
    "        if \"Docente\" in unformated_line[j]:\n",
    "            docente_position = j\n",
    "    return(docente_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(path_to_file) as pdf:\n",
    "       \n",
    "    for i in range(1500, 1994):\n",
    "        page = pdf.pages[i]\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        if \"Inscritos: 69770\" in text: #Verifica se é a última página\n",
    "            for i in range(8, 23):\n",
    "                unformated_line = text.split('\\n')[i].split(' ')\n",
    "                all_lines_to_dataframe.append([\" \".join(unformated_line[find_cargo_column(unformated_line):-1]), unformated_line[-1]])\n",
    "        else:\n",
    "            counter = 0\n",
    "            limit_line_number = 0\n",
    "            for line in text.split('\\n'):\n",
    "                counter = counter + 1\n",
    "                if \"Tipo de Vaga\" in line:\n",
    "                    limit_line_number = counter\n",
    "           \n",
    "            for i in range(8, limit_line_number-1):\n",
    "                unformated_line = text.split('\\n')[i].split(' ')\n",
    "                all_lines_to_dataframe.append([\" \".join(unformated_line[find_cargo_column(unformated_line):-1]), unformated_line[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando o dataframe inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_lines_to_dataframe)\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de uma arquivo .csv com os dados sobre Cargo e Tipo de Vaga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Marica_Cargo_TipoVaga.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise prévia do arquivo csv gerado a partir dos dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_csv = pd.read_csv(\"Marica_Cargo_TipoVaga.csv\")\n",
    "df_from_csv = df_from_csv[[\"Cargo\", \"TipoVaga\"]]\n",
    "df_from_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupando os dados por Cargo e gerando um json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data_1 = df_from_csv.groupby([\"Cargo\"]).size().reset_index(name=\"Total\")\n",
    "grouped_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped_data_1.to_json(orient='records', force_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
